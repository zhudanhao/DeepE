0 train loss: 17.205914
1 train loss: 9.898631
2 train loss: 9.038238
3 train loss: 7.7024016
4 train loss: 6.236394
5 train loss: 5.1996427
6 train loss: 4.488642
7 train loss: 3.967452
8 train loss: 3.590841
9 train loss: 3.3110132
10 train loss: 3.1009572
valid {'mr': 4099.177818061964, 'mrr': 0.3388872835770684, 'hits@1': 0.27752142386288725, 'hits@10': 0.4362228081740277}
test {'mr': 4239.449266113593, 'mrr': 0.3383157310729799, 'hits@1': 0.2750478621569879, 'hits@10': 0.4387364390555201}
11 train loss: 2.943261
12 train loss: 2.837748
13 train loss: 2.7496493
14 train loss: 2.6887727
15 train loss: 2.6326096
16 train loss: 2.5871203
17 train loss: 2.557238
18 train loss: 2.5277634
19 train loss: 2.5008783
20 train loss: 2.4796424
valid {'mr': 3383.078773895847, 'mrr': 0.38045554916420804, 'hits@1': 0.32036914963744234, 'hits@10': 0.47808174027686223}
test {'mr': 3443.0304722399487, 'mrr': 0.38213325284720345, 'hits@1': 0.3232291001914486, 'hits@10': 0.47830248883216336}
21 train loss: 2.4643972
22 train loss: 2.4530208
23 train loss: 2.4371188
24 train loss: 2.4267104
25 train loss: 2.405956
26 train loss: 2.3931093
27 train loss: 2.3903184
28 train loss: 2.3791552
29 train loss: 2.375386
30 train loss: 2.3705354
valid {'mr': 2984.556526038233, 'mrr': 0.40008805485007287, 'hits@1': 0.34377059986816083, 'hits@10': 0.4963744232036915}
test {'mr': 3227.269144862795, 'mrr': 0.3995285024585589, 'hits@1': 0.34365028717294194, 'hits@10': 0.49457562220804085}
31 train loss: 2.3562565
32 train loss: 2.350185
33 train loss: 2.3319263
34 train loss: 2.321294
35 train loss: 2.2979896
36 train loss: 2.2818816
37 train loss: 2.2730715
38 train loss: 2.2515638
39 train loss: 2.239836
40 train loss: 2.228612
valid {'mr': 2590.537244561635, 'mrr': 0.43973379930072976, 'hits@1': 0.3994726433750824, 'hits@10': 0.515161502966381}
test {'mr': 2741.794671346522, 'mrr': 0.44104467538207204, 'hits@1': 0.3998085513720485, 'hits@10': 0.517230376515635}
41 train loss: 2.2087963
42 train loss: 2.1570997
43 train loss: 2.12174
44 train loss: 2.0930197
45 train loss: 2.0944421
46 train loss: 2.0947385
47 train loss: 2.0851917
48 train loss: 2.087404
49 train loss: 2.0825782
50 train loss: 2.0814035
valid {'mr': 2575.911502966381, 'mrr': 0.4543212427114555, 'hits@1': 0.4100197758734344, 'hits@10': 0.5360909690177983}
test {'mr': 2720.0390874282066, 'mrr': 0.4576553744737245, 'hits@1': 0.4143267389917039, 'hits@10': 0.5357370772176133}
51 train loss: 2.0743763
52 train loss: 2.0852554
53 train loss: 2.0784614
54 train loss: 2.0756233
55 train loss: 2.0743628
56 train loss: 2.074112
57 train loss: 2.07343
58 train loss: 2.068267
59 train loss: 2.0712066
60 train loss: 2.0629365
valid {'mr': 2371.1128872775216, 'mrr': 0.45369274571659646, 'hits@1': 0.40754779169413313, 'hits@10': 0.5367501647989453}
test {'mr': 2560.177568602425, 'mrr': 0.45672918461029877, 'hits@1': 0.4101786853860881, 'hits@10': 0.5430759412890874}
61 train loss: 2.0667145
62 train loss: 2.0660086
63 train loss: 2.0638728
64 train loss: 2.063813
65 train loss: 2.0590727
66 train loss: 2.0644958
67 train loss: 2.056187
68 train loss: 2.0553355
69 train loss: 2.0641825
70 train loss: 2.0552423
valid {'mr': 2524.715886618326, 'mrr': 0.45774339061503944, 'hits@1': 0.41381015161502965, 'hits@10': 0.5426829268292683}
test {'mr': 2618.398213146139, 'mrr': 0.4562084093812092, 'hits@1': 0.41097638800255265, 'hits@10': 0.5390874282067645}
71 train loss: 2.0542288
72 train loss: 2.0548398
73 train loss: 2.0509467
74 train loss: 2.0509193
75 train loss: 2.0452275
76 train loss: 2.0520537
77 train loss: 2.0424547
78 train loss: 2.0547626
79 train loss: 2.044083
80 train loss: 2.0385492
valid {'mr': 2597.735003295979, 'mrr': 0.4572201765690674, 'hits@1': 0.41331575477916943, 'hits@10': 0.540210942649967}
test {'mr': 2705.381461391193, 'mrr': 0.45350927327852686, 'hits@1': 0.4076260370134014, 'hits@10': 0.5405232929164008}
81 train loss: 2.0429406
82 train loss: 2.0419202
83 train loss: 2.0369437
84 train loss: 2.039454
85 train loss: 2.0392826
86 train loss: 2.038998
87 train loss: 2.036158
88 train loss: 2.030761
89 train loss: 2.0401232
90 train loss: 2.0345275
valid {'mr': 2409.0064271588662, 'mrr': 0.45578084334111574, 'hits@1': 0.40985497692814765, 'hits@10': 0.5425181278839816}
test {'mr': 2543.7281429483087, 'mrr': 0.459163110351013, 'hits@1': 0.4114550095724314, 'hits@10': 0.5473835354179962}
91 train loss: 2.0317037
92 train loss: 2.0373924
93 train loss: 2.0345457
94 train loss: 2.034219
Epoch 00095: reducing learning rate of group 0 to 5.0000e-04.
95 train loss: 1.782333
96 train loss: 1.660896
97 train loss: 1.646182
98 train loss: 1.6448812
99 train loss: 1.651421
100 train loss: 1.6664913
valid {'mr': 2493.9828609096903, 'mrr': 0.47059648781943664, 'hits@1': 0.42963085036255766, 'hits@10': 0.5491100856954515}
test {'mr': 2549.0071793235484, 'mrr': 0.4766392238331985, 'hits@1': 0.4321952776005105, 'hits@10': 0.5588704530950862}
101 train loss: 1.6735001
102 train loss: 1.6925162
103 train loss: 1.6981153
104 train loss: 1.7065756
Epoch 00105: reducing learning rate of group 0 to 2.5000e-04.
105 train loss: 1.5624009
106 train loss: 1.5052935
107 train loss: 1.4951501
108 train loss: 1.4851626
109 train loss: 1.4836051
110 train loss: 1.480436
valid {'mr': 2338.7205009887934, 'mrr': 0.4783343915630208, 'hits@1': 0.43951878707976266, 'hits@10': 0.5520764667106131}
test {'mr': 2463.173101467773, 'mrr': 0.4825536795763854, 'hits@1': 0.44128908742820677, 'hits@10': 0.5625398851308232}
111 train loss: 1.4849019
112 train loss: 1.4858199
113 train loss: 1.4874306
114 train loss: 1.4941797
115 train loss: 1.4949875
116 train loss: 1.4954318
Epoch 00117: reducing learning rate of group 0 to 1.2500e-04.
117 train loss: 1.4038725
118 train loss: 1.3832395
119 train loss: 1.3773688
120 train loss: 1.3745333
valid {'mr': 2288.2911997363217, 'mrr': 0.4810086426250654, 'hits@1': 0.4431443638760712, 'hits@10': 0.551417270929466}
test {'mr': 2417.8008934269305, 'mrr': 0.48513793885705925, 'hits@1': 0.44336311423101465, 'hits@10': 0.564773452456924}
121 train loss: 1.3707641
122 train loss: 1.3679152
123 train loss: 1.3674178
124 train loss: 1.3679314
125 train loss: 1.3685746
126 train loss: 1.36769
127 train loss: 1.3652822
128 train loss: 1.3664297
129 train loss: 1.3642018
130 train loss: 1.3663149
valid {'mr': 2261.1020105471325, 'mrr': 0.4800527407913481, 'hits@1': 0.4424851680949242, 'hits@10': 0.5505932762030323}
test {'mr': 2428.614550095724, 'mrr': 0.4857695815053326, 'hits@1': 0.4447989789406509, 'hits@10': 0.5646139119336312}
131 train loss: 1.3662046
132 train loss: 1.3648299
133 train loss: 1.3654555
134 train loss: 1.3670233
135 train loss: 1.3672416
Epoch 00136: reducing learning rate of group 0 to 6.2500e-05.
136 train loss: 1.3141824
137 train loss: 1.3046341
138 train loss: 1.2992494
139 train loss: 1.2969778
140 train loss: 1.2953708
valid {'mr': 2222.18111404087, 'mrr': 0.48011205862637363, 'hits@1': 0.44100197758734344, 'hits@10': 0.551417270929466}
test {'mr': 2405.202137843012, 'mrr': 0.48589098424792737, 'hits@1': 0.4438417358008934, 'hits@10': 0.5678047223994894}
141 train loss: 1.295623
142 train loss: 1.2953731
143 train loss: 1.292867
144 train loss: 1.2917929
145 train loss: 1.2920854
146 train loss: 1.2905384
147 train loss: 1.2894256
148 train loss: 1.2895768
149 train loss: 1.2905574
150 train loss: 1.2892774
valid {'mr': 2215.0037903757416, 'mrr': 0.48019158811340046, 'hits@1': 0.4421555702043507, 'hits@10': 0.553394858272907}
test {'mr': 2411.7110721123167, 'mrr': 0.4861571053293561, 'hits@1': 0.44416081684747927, 'hits@10': 0.5658902361199745}
151 train loss: 1.2914073
152 train loss: 1.2872081
153 train loss: 1.2856306
154 train loss: 1.2870486
155 train loss: 1.287308
156 train loss: 1.2869979
157 train loss: 1.2866684
158 train loss: 1.2857705
159 train loss: 1.287553
Epoch 00160: reducing learning rate of group 0 to 3.1250e-05.
160 train loss: 1.2580298
valid {'mr': 2202.317073170732, 'mrr': 0.48146264089187835, 'hits@1': 0.44396835860250494, 'hits@10': 0.5537244561634805}
test {'mr': 2386.126356094448, 'mrr': 0.4861811084352571, 'hits@1': 0.4447989789406509, 'hits@10': 0.5665283982131462}
161 train loss: 1.2510997
162 train loss: 1.2524323
163 train loss: 1.2524036
164 train loss: 1.2487932
165 train loss: 1.2472776
166 train loss: 1.2492843
167 train loss: 1.2472298
168 train loss: 1.2482907
169 train loss: 1.248348
170 train loss: 1.2457045
valid {'mr': 2200.1133816743572, 'mrr': 0.4810496996121201, 'hits@1': 0.4436387607119314, 'hits@10': 0.5520764667106131}
test {'mr': 2385.0118059987235, 'mrr': 0.4863992421949835, 'hits@1': 0.4444798978940651, 'hits@10': 0.566847479259732}
171 train loss: 1.2476004
172 train loss: 1.2453812
173 train loss: 1.2448704
174 train loss: 1.2429893
175 train loss: 1.2428458
176 train loss: 1.2445055
177 train loss: 1.2441851
178 train loss: 1.241536
179 train loss: 1.2418809
180 train loss: 1.2422503
valid {'mr': 2220.811470006592, 'mrr': 0.4798380588104869, 'hits@1': 0.4416611733684904, 'hits@10': 0.5522412656558998}
test {'mr': 2394.843809827696, 'mrr': 0.4868104391995414, 'hits@1': 0.44575622208040844, 'hits@10': 0.5666879387364391}
181 train loss: 1.2408522
182 train loss: 1.2412113
183 train loss: 1.2408547
184 train loss: 1.2422799
185 train loss: 1.2416933
186 train loss: 1.239068
187 train loss: 1.2396775
188 train loss: 1.2424407
189 train loss: 1.2404763
190 train loss: 1.2377416
valid {'mr': 2191.3704680290048, 'mrr': 0.48070767561540845, 'hits@1': 0.44297956493078444, 'hits@10': 0.553394858272907}
test {'mr': 2375.2142629227824, 'mrr': 0.4866655699984278, 'hits@1': 0.4455966815571155, 'hits@10': 0.5650925335035099}
191 train loss: 1.2406782
192 train loss: 1.238364
193 train loss: 1.2374446
194 train loss: 1.2372329
195 train loss: 1.2379506
196 train loss: 1.2361472
197 train loss: 1.2357287
198 train loss: 1.2378036
199 train loss: 1.2356176
final result {'mr': 2387.219687300574, 'mrr': 0.48690391261111365, 'hits@1': 0.44463943841735803, 'hits@10': 0.5663688576898532}